
# ðŸ¦… SANTIS CLUB SERVER v4.5 (SENTINEL V3 ULTRA CORE)
# UTF-8 IRONCLAD | ASYNC I/O | HYBRID ENGINE

import os
import json
import csv
import logging
import uvicorn
import asyncio
import subprocess
from pathlib import Path

# WINDOWS ASYNCIO FIX (Playwright Support)
import sys
if sys.platform == 'win32':
    asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())
    print("âœ… Enforced WindowsProactorEventLoopPolicy")

from fastapi import FastAPI, HTTPException, Request, WebSocket, WebSocketDisconnect, Body, BackgroundTasks
from fastapi.responses import JSONResponse, FileResponse, RedirectResponse, StreamingResponse
from fastapi.middleware.cors import CORSMiddleware
import sentinel
from sentinel import sentinel_manager # New Manager
import auto_fixer
import ai_suggestions
import sitemap_generator
import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin, urlparse
from fastapi.staticfiles import StaticFiles
from reportlab.lib.pagesizes import A4
from reportlab.pdfgen import canvas
from reportlab.lib.colors import black, red, orange, green, HexColor
from reportlab.lib import colors
from pydantic import BaseModel, ConfigDict
from typing import List, Optional
from concurrent.futures import ThreadPoolExecutor
from content_sync import (
    sync_product_to_site_json,
    remove_product_from_site_json,
    slug_exists,
    load_redirects,
    save_redirects,
)

# Try to import aiofiles, fallback to executor if missing
try:
    import aiofiles
    HAS_AIOFILES = True
except ImportError:
    HAS_AIOFILES = False

# Import Audit Engine (Ensure it exists or handle gracefully)
try:
    from audit_engine import AuditEngine
except ImportError:
    AuditEngine = None

# NEW DEEP AUDIT ENGINE
try:
    from deep_audit import DeepAuditEngine
except ImportError:
    DeepAuditEngine = None

# ðŸ‘ï¸ VISUAL AUDIT ENGINE
try:
    from visual_audit import VisualAuditEngine
except ImportError:
    VisualAuditEngine = None

# âš¡ PERFORMANCE AUDIT ENGINE
try:
    from performance_audit import PerformanceAuditEngine
except ImportError:
    PerformanceAuditEngine = None

# ðŸ›¡ï¸ SECURITY AUDIT ENGINE
try:
    from security_audit import SecurityAuditEngine
except ImportError:
    SecurityAuditEngine = None

# ðŸ§  AI FIX SUGGESTIONS
try:
    import auto_fixer
    from ai_suggestions import generate_suggestions
except ImportError:
    generate_suggestions = None

# âš”ï¸ ATTACK SIMULATOR
try:
    from attack_simulator import AttackSimulatorEngine
except ImportError:
    AttackSimulatorEngine = None

visual_audit_instance = VisualAuditEngine() if VisualAuditEngine else None
performance_audit_instance = PerformanceAuditEngine() if PerformanceAuditEngine else None
security_audit_instance = SecurityAuditEngine() if SecurityAuditEngine else None
attack_simulator_instance = AttackSimulatorEngine() if AttackSimulatorEngine else None

# CONSTANTS
PORT = 8000
MAX_UPLOAD_SIZE = 10 * 1024 * 1024 # 10MB

# --- CONFIG ---
# Default admin panel URL in all launch scripts points to localhost:8000.
# Keep server port aligned with those scripts to avoid Chrome "chrome-error://chromewebdata"
# navigation failures when the app can't be reached.
PORT = 8000
DIRECTORY = os.path.dirname(os.path.abspath(__file__))
DB_FILE = os.path.join(DIRECTORY, "db", "services.json")
CONFIG_FILE = os.path.join(DIRECTORY, "db", "config.json")
AUDIT_SCRIPT = os.path.join(DIRECTORY, "santis_audit_cli.ps1")
AUDIT_REPORT = os.path.join(DIRECTORY, "reports", "fixed_links_report.csv")
FIX_SCRIPT = os.path.join(DIRECTORY, "fix_links.ps1")
REPORT_DIR = os.path.join(DIRECTORY, "reports")
HISTORY_FILE = Path(REPORT_DIR) / "history.json"
PAGES_DIR = os.path.join(DIRECTORY, "data", "pages")
SITE_CONTENT_FILE = os.path.join(DIRECTORY, "data", "site_content.json")
REDIRECTS_FILE = Path("data/redirects.json")

# --- LOGGING ---
logging.basicConfig(level=logging.INFO, format="%(asctime)s | %(message)s")
logger = logging.getLogger("SantisServer")

# --- APP ---
app = FastAPI(title="Santis Sentinel V3", version="4.5")

# --- MIDDLEWARES (SECURITY HARDENING) ---
from starlette.middleware.base import BaseHTTPMiddleware
from fastapi.responses import Response

# 1. Block Sensitive Paths
@app.middleware("http")
async def block_sensitive_paths(request: Request, call_next):
    blocked = [".env", ".git", ".vscode", "server.py", "deep_audit.py", "ai_suggestions.py", "security_audit.py"]
    path = request.url.path.lower()

    if any(b in path for b in blocked):
        logger.warning(f"ðŸš« Blocked access to sensitive path: {path}")
        return Response(content="Forbidden", status_code=403)

    return await call_next(request)

# 2. Security Headers (Ironclad)
class SecurityHeadersMiddleware(BaseHTTPMiddleware):
    async def dispatch(self, request, call_next):
        response = await call_next(request)
        
        # CSP: Allow self, data, https, and inline styles/scripts for now (Migration Phase)
        # Prod-grade strict CSP requires moving all inline scripts to files.
        response.headers["Content-Security-Policy"] = (
            "default-src 'self'; "
            "img-src 'self' data: https:; "
            "script-src 'self' 'unsafe-inline' 'unsafe-eval' https://cdn.jsdelivr.net; " # unsafe-eval needed for some older libs
            "style-src 'self' 'unsafe-inline' https://cdn.jsdelivr.net; "
            "connect-src 'self' https://cdn.jsdelivr.net; "
            "font-src 'self' https: data:;"
        )
        
        # Clickjacking Protection
        response.headers["X-Frame-Options"] = "DENY"
        
        # MIME Sniffing Protection
        response.headers["X-Content-Type-Options"] = "nosniff"
        
        # Referrer Policy
        response.headers["Referrer-Policy"] = "strict-origin-when-cross-origin"
        
        # HSTS (Enable in Prod - Active now per user request)
        response.headers["Strict-Transport-Security"] = "max-age=31536000; includeSubDomains"
        
        return response

app.add_middleware(SecurityHeadersMiddleware)

# --- AUTO SECURITY PATCH ENDPOINT ---
@app.get("/admin/auto-security-patch")
async def auto_security_patch_status():
    return {
        "status": "ACTIVE",
        "headers_enabled": [
            "CSP",
            "X-Frame-Options",
            "HSTS",
            "X-Content-Type-Options",
            "Referrer-Policy"
        ],
        "sensitive_paths_blocked": True
    }


# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- STARTUP EVENT (PHASE 20: MULTI-SITE) ---
@app.on_event("startup")
async def startup_event():
    logger.info("ðŸŒ Starting Sentinel Multi-Site Ecosystem...")
    asyncio.create_task(sentinel_manager.start())

# --- REDIRECT MIDDLEWARE ---
@app.middleware("http")
async def redirect_middleware(request: Request, call_next):
    if REDIRECTS_FILE.exists():
        try:
            with REDIRECTS_FILE.open("r", encoding="utf-8") as f:
                redirects = json.load(f).get("redirects", [])
            path = request.url.path
            for rule in redirects:
                if rule.get("from") == path:
                    return RedirectResponse(url=rule.get("to"), status_code=rule.get("type", 301))
        except Exception as e:
            logger.error(f"Redirect middleware error: {e}")
    return await call_next(request)

# --- ASYNC HELPERS (UTF-8 IRONCLAD) ---
executor = ThreadPoolExecutor(max_workers=4)

# --- WEBSOCKET MANAGER (Brain Link) ---
class ConnectionManager:
    def __init__(self):
        self.active: set[WebSocket] = set()

    async def connect(self, websocket: WebSocket):
        await websocket.accept()
        self.active.add(websocket)

    def disconnect(self, websocket: WebSocket):
        try:
            self.active.remove(websocket)
        except KeyError:
            pass

    async def broadcast(self, message: str):
        stale = []
        for ws in self.active:
            try:
                await ws.send_text(message)
            except Exception:
                stale.append(ws)
        for ws in stale:
            self.disconnect(ws)

manager = ConnectionManager()

async def read_file_async(path):
    if not os.path.exists(path): return None
    try:
        if HAS_AIOFILES:
            async with aiofiles.open(path, mode='r', encoding='utf-8') as f:
                return await f.read()
        else:
            # Fallback to thread pool for blocking I/O
            loop = asyncio.get_event_loop()
            with open(path, 'r', encoding='utf-8') as f:
                return await loop.run_in_executor(executor, f.read)
    except Exception as e:
        logger.error(f"Read Error {path}: {e}")
        return None

async def write_file_async(path, content):
    try:
        if HAS_AIOFILES:
            async with aiofiles.open(path, mode='w', encoding='utf-8') as f:
                await f.write(content)
        else:
            loop = asyncio.get_event_loop()
            def _write():
                with open(path, 'w', encoding='utf-8') as f:
                    f.write(content)
            await loop.run_in_executor(executor, _write)
        return True
    except Exception as e:
        logger.error(f"Write Error {path}: {e}")
        return False

# --- JSON HELPERS ---
async def read_json(path):
    content = await read_file_async(path)
    if not content: return []
    try:
        return json.loads(content.lstrip("\ufeff"))
    except Exception as e:
        logger.error(f"JSON Parse Error {path}: {e}")
        return []

async def save_json(path, data):
    try:
        content = json.dumps(data, ensure_ascii=False, indent=4)
        return await write_file_async(path, content)
    except Exception as e:
        logger.error(f"JSON Serialize Error {path}: {e}")
        return False

def is_safe_path(base_dir, target_path):
    try:
        base = os.path.abspath(base_dir)
        target = os.path.abspath(target_path)
        return os.path.commonpath([base]) == os.path.commonpath([base, target])
    except Exception:
        return False

# --- WEBSOCKET ENDPOINT ---
@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    """
    Lightweight Brain link so frontend no longer throws
    connection errors when the server is up.
    - Echoes incoming JSON/text with an ack
    - Broadcasts messages to other active peers (bestâ€‘effort)
    """
    await manager.connect(websocket)
    logger.info("ðŸ”Œ WS client connected")
    try:
        while True:
            message = await websocket.receive_text()
            try:
                payload = json.loads(message)
            except json.JSONDecodeError:
                payload = {"text": message}

            ack = json.dumps({"type": "ack", "payload": payload, "source": "server"})
            await websocket.send_text(ack)
            await manager.broadcast(json.dumps({"type": "relay", "payload": payload, "source": "cloud"}))
    except WebSocketDisconnect:
        logger.info("âš ï¸ WS client disconnected")
        manager.disconnect(websocket)
    except Exception as e:
        logger.error(f"WS error: {e}")
        manager.disconnect(websocket)

# --- JSON-LD SCHEMA (Service) ---
SCHEMA_PROVIDER = {
    "@type": "Spa",
    "name": "Santis Spa"
}

SCHEMA_AREA = {
    "@type": "Country",
    "name": "Turkey"
}

PREFERRED_CANONICAL_ORDER = ["en", "tr", "de"]

# --- MODELS ---
class ServiceItem(BaseModel):
    id: str | int
    slug: str
    title: Optional[str] = None # V3 Unified
    name: Optional[str] = None  # Legacy
    desc: Optional[str] = ""
    category: str
    cultural_world: Optional[str] = None
    image: str
    price: Optional[str | int] = None
    tags: List[str] = []
    badge: Optional[str] = None
    # Allow flexible dict (Pydantic v2 style)
    model_config = ConfigDict(extra="allow")

# --- ENDPOINTS ---

@app.get("/api/services")
async def get_services():
    """Get Services via Async JSON"""
    data = await read_json(DB_FILE)
    if isinstance(data, dict): return list(data.values())
    return data

@app.post("/api/services")
async def save_services(items: List[dict]): # Accept dict to be flexible
    """Save Services to JSON (Async)"""
    # Slug conflict guard
    seen = {}
    duplicates = []
    for item in items:
        slug = str(item.get("slug") or item.get("id") or "").strip().lower()
        if not slug:
            continue
        if slug in seen:
            duplicates.append(slug)
        else:
            seen[slug] = True
        # Existing data conflict only when adding single new item (common admin path)
        if len(items) == 1 and slug_exists(slug):
            raise HTTPException(
                status_code=409,
                detail={"error": "slug_exists", "message": "Bu slug zaten kullanÄ±lÄ±yor.", "slug": slug}
            )
    if duplicates:
        raise HTTPException(
            status_code=400,
            detail={"error": "duplicate_slug", "slugs": list(set(duplicates))}
        )

    if await save_json(DB_FILE, items):
        try:
            loop = asyncio.get_event_loop()
            # Run sync in executor to avoid blocking
            await loop.run_in_executor(None, lambda: [sync_product_to_site_json(item) for item in items])
        except Exception as e:
            logger.error(f"Site content sync failed: {e}")
        return {"status": "saved", "count": len(items)}
    raise HTTPException(status_code=500, detail="Failed to save file")

@app.delete("/api/services/{slug}")
async def delete_service(slug: str):
    """Delete service from JSON and site content"""
    data = await read_json(DB_FILE)
    if isinstance(data, list):
        data = [s for s in data if str(s.get("slug") or s.get("id")) != str(slug)]
        await save_json(DB_FILE, data)
    # Sync removal to site_content
    loop = asyncio.get_event_loop()
    await loop.run_in_executor(None, lambda: remove_product_from_site_json(slug))
    return {"status": "deleted", "slug": slug}

# --- HREFLANG LOOKUP API ---
@app.get("/api/hreflang/{group_id}")
async def get_hreflang(group_id: str):
    data = await read_json(SITE_CONTENT_FILE)
    if not isinstance(data, dict):
        return {"alternates": []}
    alternates = []
    languages = data.get("languages", {})
    for lang, lang_data in languages.items():
        sections = (lang_data or {}).get("sections", {})
        for section, sec_data in sections.items():
            for item in (sec_data or {}).get("items", []):
                gid = item.get("group_id") or item.get("id")
                if gid == group_id:
                    slug = item.get("id")
                    if slug:
                        alternates.append({
                            "lang": lang,
                            "url": f"/{lang}/{section}/{slug}"
                    })
    return {"alternates": alternates}

@app.get("/api/canonical/{group_id}")
async def get_canonical(group_id: str):
    data = await read_json(SITE_CONTENT_FILE)
    if not isinstance(data, dict):
        return {"canonical": None}

    languages = data.get("languages", {})

    for lang in PREFERRED_CANONICAL_ORDER:
        lang_data = languages.get(lang) or {}
        sections = lang_data.get("sections", {})
        for section, sec_data in sections.items():
            for item in (sec_data or {}).get("items", []):
                gid = item.get("group_id") or item.get("id") or item.get("slug")
                slug = item.get("id") or item.get("slug")
                if gid == group_id and slug:
                    return {"canonical": f"/{lang}/{section}/{slug}"}

    return {"canonical": None}


@app.get("/api/schema/{group_id}")
async def get_schema(group_id: str, request: Request):
    """
    Return Service + LocalBusiness schema graph for the given group_id.
    Uses the same language/section structure as hreflang/canonical.
    """
    data = await read_json(SITE_CONTENT_FILE)
    if not isinstance(data, dict):
        return {}

    base_url = str(request.base_url).rstrip("/")
    languages = data.get("languages", {})

    # iterate preferred order first
    for lang in PREFERRED_CANONICAL_ORDER + [l for l in languages.keys() if l not in PREFERRED_CANONICAL_ORDER]:
        lang_data = languages.get(lang) or {}
        sections = lang_data.get("sections", {})
        for section, sec_data in sections.items():
            for item in (sec_data or {}).get("items", []):
                gid = item.get("group_id") or item.get("id") or item.get("slug")
                slug = item.get("id") or item.get("slug")
                if gid == group_id and slug:
                    rating_value = item.get("rating_value", 4.9)
                    rating_count = item.get("rating_count", 120)
                    page_url = f"{base_url}/{lang}/{section}/{slug}"
                    business_id = f"{base_url}/#business"

                    return {
                        "@context": "https://schema.org",
                        "@graph": [
                            {
                                "@type": "Service",
                                "@id": f"{page_url}#service",
                                "name": item.get("title") or item.get("name") or slug,
                                "description": item.get("description") or item.get("desc") or "",
                                "image": item.get("image") or item.get("img"),
                                "url": page_url,
                                "provider": {"@id": business_id},
                                "areaServed": SCHEMA_AREA,
                                "aggregateRating": {
                                    "@type": "AggregateRating",
                                    "ratingValue": rating_value,
                                    "reviewCount": rating_count
                                },
                                "review": [
                                    {
                                        "@type": "Review",
                                        "author": {"@type": "Person", "name": "Guest"},
                                        "reviewRating": {"@type": "Rating", "ratingValue": "5"},
                                        "reviewBody": "Amazing experience, highly relaxing and professional service."
                                    }
                                ]
                            },
                            {
                                "@type": "Spa",
                                "@id": business_id,
                                "name": "Santis Spa & Wellness",
                                "url": base_url,
                                "logo": f"{base_url}/assets/img/logo.png",
                                "image": f"{base_url}/assets/img/spa-interior.jpg",
                                "telephone": "+90 534 835 0169",
                                "priceRange": "$$$",
                                "address": {
                                    "@type": "PostalAddress",
                                    "streetAddress": "Side, Antalya",
                                    "addressLocality": "Side",
                                    "addressCountry": "TR"
                                },
                                "geo": {
                                    "@type": "GeoCoordinates",
                                    "latitude": "36.8841",
                                    "longitude": "30.7056"
                                },
                                "openingHoursSpecification": [
                                    {
                                        "@type": "OpeningHoursSpecification",
                                        "dayOfWeek": [
                                            "Monday",
                                            "Tuesday",
                                            "Wednesday",
                                            "Thursday",
                                            "Friday",
                                            "Saturday"
                                        ],
                                        "opens": "10:00",
                                        "closes": "22:00"
                                    },
                                    {
                                        "@type": "OpeningHoursSpecification",
                                        "dayOfWeek": "Sunday",
                                        "opens": "11:00",
                                        "closes": "20:00"
                                    }
                                ],
                                "sameAs": [
                                    "https://www.instagram.com/santis",
                                    "https://www.facebook.com/santis"
                                ]
                            }
                        ]
                    }

    return {}

# --- REDIRECT MANAGEMENT API ---
@app.get("/admin/redirects")
def list_redirects():
    return load_redirects()

@app.post("/admin/redirects/add")
def add_redirect(data: dict = Body(...)):
    redirects = load_redirects()
    redirects["redirects"].append({
        "from": data.get("from"),
        "to": data.get("to"),
        "type": data.get("type", 301)
    })
    save_redirects(redirects)
    return {"status": "ok"}

@app.post("/admin/redirects/delete")
def delete_redirect(data: dict = Body(...)):
    redirects = load_redirects()
    redirects["redirects"] = [
        r for r in redirects.get("redirects", [])
        if not (r.get("from") == data.get("from") and r.get("to") == data.get("to"))
    ]
    save_redirects(redirects)
    return {"status": "deleted"}

@app.get("/api/config")
async def get_config():
    """Get Config via Async JSON"""
    conf = await read_json(CONFIG_FILE)
    if not conf:
        return {
            "site_mode": "production",
            "animation_level": "high",
            "maintenance_mode": False,
            "modules": {"soul_engine": True}
        }
    return conf

@app.post("/api/config")
async def save_config(cfg: dict):
    """Save Config (Async)"""
    if await save_json(CONFIG_FILE, cfg):
         return {"status": "saved"}
    raise HTTPException(status_code=500, detail="Save failed")

# --- HEALTH CHECK ---
@app.get("/health")
async def health():
    return {"status": "ok", "system": "SantisOS v4.5", "mode": "json-core"}

# --- PAGE BUILDER API (file-based storage) ---
def ensure_pages_dir():
    os.makedirs(PAGES_DIR, exist_ok=True)

def page_path(slug: str) -> str:
    safe_slug = "".join(ch for ch in slug if ch.isalnum() or ch in ("-", "_")).lower()
    return os.path.join(PAGES_DIR, f"{safe_slug}.json")

@app.get("/api/pages/{slug}")
async def get_page(slug: str):
    """Return blocks for requested page; empty shell if missing."""
    ensure_pages_dir()
    path = page_path(slug)
    if not os.path.exists(path):
        return {"slug": slug, "title": "Yeni Sayfa", "blocks": [], "seo": {}}
    try:
        async with aiofiles.open(path, 'r', encoding='utf-8') as f:
            return json.loads(await f.read())
    except Exception as e:
        logger.error(f"Page read error {slug}: {e}")
        raise HTTPException(status_code=500, detail="Page read error")

@app.post("/api/pages/{slug}")
async def save_page(slug: str, body: dict):
    """Persist page blocks for builder (no auth yet)."""
    ensure_pages_dir()
    path = page_path(slug)
    try:
        async with aiofiles.open(path, 'w', encoding='utf-8') as f:
            await f.write(json.dumps(body, ensure_ascii=False, indent=2))
        return {"status": "saved", "slug": slug}
    except Exception as e:
        logger.error(f"Page save error {slug}: {e}")
        raise HTTPException(status_code=500, detail="Page save error")

# --- SITE CONTENT NORMALIZER (global -> sections) ---
@app.post("/admin/sections/sync")
async def normalize_site_content():
    """
    Ensures data/site_content.json contains sections.* items.
    Non-destructive: only adds 'sections' when missing.
    """
    data = await read_json(SITE_CONTENT_FILE)
    if not data:
        raise HTTPException(status_code=404, detail="site_content.json not found or empty")

    # Already present
    if isinstance(data, dict) and data.get("sections"):
        return {"status": "ok", "message": "sections already present", "counts": {
            "masaj": len(data["sections"].get("masaj", {}).get("items", [])) if isinstance(data["sections"], dict) else 0,
            "hamam": len(data["sections"].get("hamam", {}).get("items", [])) if isinstance(data["sections"], dict) else 0,
            "skin": len(data["sections"].get("skin", {}).get("items", [])) if isinstance(data["sections"], dict) else 0,
        }}

    if not isinstance(data, dict) or "global" not in data:
        raise HTTPException(status_code=400, detail="Legacy format missing 'global' key")

    try:
        all_items = []
        for v in data["global"].values():
            if isinstance(v, list):
                all_items.extend(v)
        sections = {
            "masaj": {"items": [i for i in all_items if isinstance(i, dict) and i.get("category") == "masaj"]},
            "hamam": {"items": [i for i in all_items if isinstance(i, dict) and i.get("category") == "hamam"]},
            "skin":  {"items": [i for i in all_items if isinstance(i, dict) and i.get("category") in ("skin", "cilt")]},
        }
        data["sections"] = sections
        if await save_json(SITE_CONTENT_FILE, data):
            return {"status": "saved", "counts": {k: len(v["items"]) for k, v in sections.items()}}
    except Exception as e:
        logger.error(f"Section sync error: {e}")
        raise HTTPException(status_code=500, detail="Failed to generate sections")

    raise HTTPException(status_code=500, detail="Unknown save error")

# --- AUDIT ENDPOINTS ---

@app.get("/admin/audit-stream")
async def audit_stream(request: Request):
    """
    Sentinel V3 Flash Scan Stream.
    Uses AuditEngine with Async generators.
    """
    if not AuditEngine:
        # Fallback generator if engine missing
        async def mock_gen():
             yield 'data: {"type":"error", "message":"AuditEngine module missing"}\n\n'
             yield 'data: {"type":"done", "score":0, "errors":[]}\n\n'
        return StreamingResponse(mock_gen(), media_type="text/event-stream")

    engine = AuditEngine(DIRECTORY)
    return StreamingResponse(engine.run_flash_scan(), media_type="text/event-stream")

@app.post("/admin/run-audit")
async def run_audit(request: Request):
    """Python-based link audit (site_audit.py)"""
    script = os.path.join(DIRECTORY, "site_audit.py")
    if not os.path.exists(script):
        raise HTTPException(status_code=404, detail="site_audit.py not found.")
    try:
        # PowerShell is blocking CPU, run in executor
        loop = asyncio.get_event_loop()
        env = os.environ.copy()
        if request.query_params.get("fix") == "1":
            env["AUTO_FIX"] = "1"
        
        result = await loop.run_in_executor(executor, lambda: subprocess.run(
            ["python", script],
            capture_output=True, text=True, timeout=180, encoding='utf-8', errors='replace', env=env
        ))
        
        # 2. READ STRUCTURED AUDIT DATA (AI INPUT)
        audit_json_path = os.path.join(DIRECTORY, "reports", "audit_result.json")
        audit_data = {}
        suggestions = []

        if os.path.exists(audit_json_path):
            try:
                async with aiofiles.open(audit_json_path, 'r', encoding='utf-8') as f:
                    content = await f.read()
                    audit_data = json.loads(content)
                
                # 3. GENERATE AI SUGGESTIONS
                if generate_suggestions:
                    try:
                        suggestions = generate_suggestions(audit_data)
                    except Exception as ai_err:
                        logger.error(f"AI Gen Error: {ai_err}")
                        suggestions = [{"issue": "AI Motoru HatasÄ±", "priority": "LOW", "fix": str(ai_err)}]
                
            except Exception as e:
                logger.error(f"Audit JSON Read Error: {e}")

        return {
            "status": "success", 
            "result": result.stdout,
            "errors": result.stderr,
            "audit_data": audit_data,
            "suggestions": suggestions
        }
    except Exception as e:
        logger.error(f"Audit Run Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/admin/auto-fix")
async def auto_fix_endpoint(request: Request):
    """
    Applies an automated fix.
    Body: { "action": str, "params": dict }
    """
    try:
        data = await request.json()
        action = data.get("action")
        params = data.get("params", {})
        
        if not action:
            return JSONResponse({"status": "error", "message": "Missing 'action' field"}, status_code=400)
            
        logger.info(f"Auto-Fix Requested: {action}")
        
        # Run in executor to avoid blocking
        loop = asyncio.get_event_loop()
        result = await loop.run_in_executor(None, lambda: auto_fixer.apply_fix(action, params))
        
        return JSONResponse(result)
        
    except Exception as e:
        logger.error(f"Auto-Fix Error: {e}")
        return JSONResponse({"status": "error", "message": str(e)}, status_code=500)


# ðŸ¤– SENTINEL BACKGROUND WORKER
# (Startup event is now at top of file via sentinel_manager)

@app.get("/admin/sentinel-status")
async def get_sentinel_status():
    # MVP: Return status of the first instance (Main Site)
    if sentinel.sentinel_manager.instances:
        return sentinel.sentinel_manager.instances[0].status
    return {"state": "OFFLINE", "health": "UNKNOWN", "message": "No Sentinel instances running"}

@app.get("/admin/sentinel/fleet")
async def get_sentinel_fleet():
    """Returns the status of all Sentinel instances in the fleet."""
    fleet = []
    for pid, instance in sentinel.sentinel_manager.registry.items():
        fleet.append({
            "id": pid,
            "status": instance.status,
            "config": instance.config_path
        })
    return {"fleet": fleet}

@app.get("/admin/sentinel/incidents")
async def get_sentinel_incidents():
    # Helper to avoid circular imports if any, or just direct access
    import sentinel_memory
    return sentinel_memory.SentinelMemory.get_recent(100)

@app.get("/admin/sentinel/download-report")
async def download_sentinel_report():
    import sentinel_pdf
    try:
        pdf_path = sentinel_pdf.SentinelPDF.generate_report()
        return FileResponse(pdf_path, media_type="application/pdf", filename="Santis_Autonomous_Report.pdf")
    except Exception as e:
        logger.error(f"Report Generation Failed: {e}")
        return JSONResponse({"status": "error", "message": str(e)}, status_code=500)

@app.get("/admin/sentinel/capabilities")
async def get_sentinel_capabilities():
    import sentinel_capabilities
    return sentinel_capabilities.SentinelCapabilities.check()

@app.get("/admin/sentinel/trends")
async def get_sentinel_trends():
    import sentinel_metrics
    return sentinel_metrics.SentinelMetrics.get_history(50)

@app.get("/admin/sentinel/suggestions")
async def get_sentinel_suggestions():
    from ai_suggestions import AISuggestionsEngine
    return {"suggestions": AISuggestionsEngine.generate()}

@app.post("/admin/sentinel/apply/{sid}")
async def apply_sentinel_suggestion(sid: str):
    from auto_optimizer import AutoOptimizer
    return AutoOptimizer.apply_suggestion(sid)

@app.post("/admin/sentinel/reject/{sid}")
async def reject_sentinel_suggestion(sid: str):
    from auto_optimizer import AutoOptimizer
    return AutoOptimizer.reject_suggestion(sid)

@app.get("/admin/sentinel/history")
async def get_sentinel_history():
    from auto_optimizer import AutoOptimizer
    return {"history": AutoOptimizer.load_impact_log()}

async def trigger_full_restore():
    """Triggers the full_system_restore.py script"""
    try:
        script_path = os.path.join(DIRECTORY, "full_system_restore.py")
        if not os.path.exists(script_path):
             raise HTTPException(status_code=404, detail="Restore script not found")
        
        # Run in background to avoid blocking
        loop = asyncio.get_event_loop()
        python_exe = sys.executable if 'sys' in globals() else 'python'
        
        def run_script():
            # Run restore script and capture output
            result = subprocess.run([python_exe, script_path], capture_output=True, text=True, encoding='utf-8')
            return result

        result = await loop.run_in_executor(None, run_script)
        
        if result.returncode == 0:
            logger.info("Full System Restore completed successfully.")
            return {"status": "success", "message": "System restored.", "logs": result.stdout}
        else:
            logger.error(f"Restore failed: {result.stderr}")
            return {"status": "error", "message": "Restore failed.", "logs": result.stderr}

    except Exception as e:
        logger.error(f"Restore API Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/admin/run-dom-audit")
async def run_dom_audit():
    """Headless DOM audit via Playwright."""
    script = os.path.join(DIRECTORY, "site_audit_dom.py")
    if not os.path.exists(script):
        raise HTTPException(status_code=404, detail="site_audit_dom.py not found.")
    try:
        loop = asyncio.get_event_loop()
        result = await loop.run_in_executor(executor, lambda: subprocess.run(
            ["python", script],
            capture_output=True, text=True, timeout=240, encoding='utf-8', errors='replace'
        ))
        return {
            "stdout": result.stdout,
            "stderr": result.stderr,
            "report": os.path.join("reports", "dom_audit_report.html")
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/audit-history")
async def audit_history():
    history_file = HISTORY_FILE
    if not history_file.exists():
        return {"data": [], "alert": False}
    try:
        content = history_file.read_text(encoding="utf-8").strip()
        if not content:
            return {"data": [], "alert": False}

        rows = []
        # Try full JSON array
        try:
            data = json.loads(content)
            if isinstance(data, list):
                rows = data
        except Exception:
            # Fallback NDJSON (one JSON per line)
            for line in content.splitlines():
                line = line.strip()
                if not line:
                    continue
                try:
                    rows.append(json.loads(line))
                except Exception:
                    continue

        rows = rows[-20:]

        alert = False
        if len(rows) >= 2:
            def get_broken(obj):
                return obj.get("broken_count") or obj.get("broken") or 0
            last = get_broken(rows[-1])
            prev = get_broken(rows[-2])
            if prev and last > prev * 1.5:
                alert = True

        return {"data": rows, "alert": alert}
    except Exception as e:
        logger.error(f"History read error: {e}")
        return {"data": [], "alert": False}

def compute_health_score(entry: dict) -> int:
    score = 100
    broken = entry.get("broken") or entry.get("broken_count") or entry.get("broken_links") or 0
    total = entry.get("checked") or entry.get("total_urls") or entry.get("total_links") or 1
    avg_ms = entry.get("avg_ms") or entry.get("avg_response_ms") or entry.get("avg_response_time") or 0
    errors_5xx = entry.get("errors_5xx") or 0

    broken_ratio = broken / max(1, total)
    score -= min(broken_ratio * 60, 60)

    if avg_ms > 1200:
        score -= 15
    elif avg_ms > 800:
        score -= 8

    score -= min(errors_5xx * 2, 15)
    return max(int(score), 0)

def load_history_rows():
    if not HISTORY_FILE.exists():
        return []
    content = HISTORY_FILE.read_text(encoding="utf-8").strip()
    if not content:
        return []
    rows = []
    try:
        data = json.loads(content)
        if isinstance(data, list):
            rows = data
    except Exception:
        for line in content.splitlines():
            line = line.strip()
            if not line:
                continue
            try:
                rows.append(json.loads(line))
            except Exception:
                continue
    return rows

@app.get("/api/health-score")
async def health_score():
    try:
        rows = load_history_rows()
        if not rows:
            return {"score": 100}
        last = rows[-1]
        score = last.get("health_score")
        if score is None:
            score = compute_health_score(last)
        return {"score": score}
    except Exception as e:
        logger.error(f"Health score error: {e}")
        return {"score": 100}

@app.get("/api/health-history")
async def health_history():
    try:
        rows = load_history_rows()
        if not rows:
            return {"scores": [], "reports": []}
        scores = []
        reports = []
        for entry in rows:
            score = entry.get("health_score")
            if score is None:
                score = compute_health_score(entry)
            scores.append(score)
            reports.append(entry.get("report"))
        return {"scores": scores[-20:], "reports": reports[-20:]}
    except Exception as e:
        logger.error(f"Health history error: {e}")
        return {"scores": [], "reports": []}

@app.get("/admin/seo-quality")
async def seo_quality():
    path = Path("reports/seo_quality.json")
    if not path.exists():
        return {}
    try:
        return json.loads(path.read_text(encoding="utf-8"))
    except Exception as e:
        logger.error(f"SEO quality read error: {e}")
        return {}

@app.post("/admin/run-seo-audit")
async def run_seo_audit():
    script = os.path.join(DIRECTORY, "seo_quality_audit.py")
    if not os.path.exists(script):
        raise HTTPException(status_code=404, detail="seo_quality_audit.py not found.")
    try:
        loop = asyncio.get_event_loop()
        result = await loop.run_in_executor(executor, lambda: subprocess.run(
            ["python", script],
            capture_output=True, text=True, timeout=120, encoding='utf-8', errors='replace'
        ))
        return {"stdout": result.stdout, "stderr": result.stderr}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/admin/run-seo-ai")
async def run_seo_ai():
    script = os.path.join(DIRECTORY, "seo_ai_fixer.py")
    if not os.path.exists(script):
        raise HTTPException(status_code=404, detail="seo_ai_fixer.py not found.")
    try:
        loop = asyncio.get_event_loop()
        result = await loop.run_in_executor(executor, lambda: subprocess.run(
            ["python", script],
            capture_output=True, text=True, timeout=120, encoding='utf-8', errors='replace'
        ))
        return {"stdout": result.stdout, "stderr": result.stderr}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/admin/seo-ai-suggestions")
async def seo_ai_suggestions():
    path = Path("reports/seo_ai_suggestions.json")
    if not path.exists():
        return {}
    try:
        return json.loads(path.read_text(encoding="utf-8"))
    except Exception as e:
        logger.error(f"SEO AI suggestions read error: {e}")
        return {}

@app.get("/admin/audit-report")
async def get_audit_report():
    """Return audit rows as JSON (Async Read)"""
    content = await read_file_async(AUDIT_REPORT)
    if not content:
         return JSONResponse(content={"error": "Report not found."}, status_code=404)

    rows_out = []
    try:
        rows = content.splitlines()
        reader = csv.DictReader(rows)
        for row in reader:
            rows_out.append(row)
    except Exception as e:
        logger.error(f"CSV Parse Error: {e}")
        return JSONResponse(content={"error": "Report parse failed."}, status_code=500)

    return rows_out

@app.get("/admin/download-report")
async def download_report():
    """Download CSV report"""
    if not os.path.exists(AUDIT_REPORT):
        return JSONResponse(content={"error": "Report not found."}, status_code=404)
    # FileResponse handles async streaming automatically in newer FastAPI, safe to use
    return FileResponse(AUDIT_REPORT, media_type="text/csv", filename="fixed_links_report.csv")

@app.post("/api/fix/link")
async def fix_link(payload: dict):
    file_path = payload.get("file", "")
    broken_url = payload.get("url", "")
    
    if not file_path or not broken_url:
        return JSONResponse(content={"success": False, "message": "Missing params"}, status_code=400)

    if not is_safe_path(DIRECTORY, file_path):
        return JSONResponse(content={"success": False, "message": "Unsafe path"}, status_code=400)

    content = await read_file_async(file_path)
    if not content:
        return JSONResponse(content={"success": False, "message": "File read error"}, status_code=404)

    if broken_url not in content:
        return JSONResponse(content={"success": False, "message": "URL not found"}, status_code=404)

    updated = content.replace(broken_url, "#")
    if await write_file_async(file_path, updated):
        return {"success": True}
    return JSONResponse(content={"success": False, "message": "Write failed"}, status_code=500)

# --- AI & UPLOAD ---

@app.post("/admin/generate-ai")
async def admin_generate_ai(payload: dict):
    """
    AI Content Stub (UTF-8 Safe).
    """
    prompt = payload.get("prompt", "")
    tone = payload.get("tone", "luxury")
    
    # Mock Response (In future: call Gemini API here)
    text = f"âœ¨ (AI {tone.upper()}) {prompt} iÃ§in oluÅŸturulan iÃ§erik... [Santis AI]"
    return {"status": "ok", "text": text}

@app.post("/admin/upload")
async def admin_upload(request: Request):
    """
    Raw Upload Handler (simpler than UploadFile for binary streams sometimes)
    """
    form = await request.form()
    file = form.get("file")
    if not file:
         return {"error": "No file"}

    uploads_dir = os.path.join(DIRECTORY, "uploads")
    os.makedirs(uploads_dir, exist_ok=True)
    
    filename = file.filename
    dest_path = os.path.join(uploads_dir, filename)
    
    # Read/Write
    contents = await file.read()
    
    # Use sync write for binary for now or executor
    with open(dest_path, "wb") as f:
        f.write(contents)

    return {"status": "uploaded", "filename": f"uploads/{filename}"}

# Import Master Cleaner & Asset Optimizer
try:
    from master_cleaner import MasterCleaner
    from asset_optimizer import AssetOptimizer
    
    master_cleaner = MasterCleaner(DIRECTORY)
    asset_optimizer = AssetOptimizer(DIRECTORY)
    logger.info("âœ… Core Systems Loaded (MasterCleaner + AssetOptimizer)")
except ImportError as e:
    logger.error(f"âŒ Core System Failed: {e}")
    master_cleaner = None
    asset_optimizer = None

# --- MASTER CLEAN ENDPOINTS ---

@app.post("/admin/fix/ghost")
async def fix_ghost_layers():
    if not master_cleaner:
        raise HTTPException(status_code=500, detail="MasterCleaner not loaded")
    
    # Run in thread pool to avoid blocking
    loop = asyncio.get_event_loop()
    result = await loop.run_in_executor(None, master_cleaner.fix_ghost_layers)
    return JSONResponse(content=result)

@app.post("/admin/fix/utf8")
async def fix_utf8_issues():
    if not master_cleaner:
        raise HTTPException(status_code=500, detail="MasterCleaner not loaded")
    
    loop = asyncio.get_event_loop()
    result = await loop.run_in_executor(None, master_cleaner.fix_utf8_issues)
    return JSONResponse(content=result)

@app.post("/admin/fix/optimize")
async def optimize_assets():
    if not asset_optimizer:
        raise HTTPException(status_code=500, detail="AssetOptimizer not loaded")

    loop = asyncio.get_event_loop()
    # threshold_kb=500 means only images > 500KB will be converted
    result = await loop.run_in_executor(None, asset_optimizer.optimize_assets, 500)
    
    # Map to Frontend API Protocol
    response = {
        "scanned": result["scanned"],
        "total_fixed": len(result["converted"]),
        "fixed_files": [item["original"] for item in result["converted"]],
        "details": result["converted"],
        "errors": result["errors"]
    }
    
    return JSONResponse(content=response)

# Public/API alias to avoid static /admin mount conflict
@app.api_route("/api/fix/{fix_type}", methods=["GET", "POST", "PUT", "DELETE", "OPTIONS"])
async def api_fix(fix_type: str):
    if fix_type == "ghost":
        return await fix_ghost_layers()
    if fix_type == "utf8":
        return await fix_utf8_issues()
    if fix_type == "optimize":
        return await optimize_assets()
    raise HTTPException(status_code=400, detail="Unknown fix type")

# Explicit endpoints (some clients cannot use path params)
@app.post("/api/fix/utf8")
async def api_fix_utf8():
    return await fix_utf8_issues()

@app.post("/api/fix/ghost")
async def api_fix_ghost():
    return await fix_ghost_layers()

@app.post("/api/fix/optimize")
async def api_fix_optimize():
    return await optimize_assets()

# Simple aliases
@app.api_route("/fix/utf8", methods=["GET", "POST"])
async def api_fix_utf8_simple():
    return await fix_utf8_issues()

@app.api_route("/fix/ghost", methods=["GET", "POST"])
async def api_fix_ghost_simple():
    return await fix_ghost_layers()

@app.api_route("/fix/optimize", methods=["GET", "POST"])
async def api_fix_optimize_simple():
    return await optimize_assets()

# --- FULL SITE AUDIT (Link, Image, SEO, Server) ---
@app.get("/admin/full-audit")
async def full_audit_endpoint():
    """
    Crawls the site and reports:
    - Broken links (404)
    - Missing images
    - Server errors (500+)
    - SEO issues (missing title/desc)
    - Fix suggestions
    Runs in threadpool.
    """
    base_url = f"http://localhost:{PORT}"
    
    def _run_full_scan():
        visited = set()
        to_visit = [base_url]

        broken_links = []
        missing_images = []
        server_errors = []
        seo_issues = []
        fix_suggestions = []

        while to_visit:
            url = to_visit.pop(0) # BFS
            if url in visited:
                continue
            visited.add(url)

            try:
                # Skip external links for deep scan, but check status if needed? 
                # User logic implies checking everything but only recursing on internal.
                
                r = requests.get(url, timeout=5)
                status = r.status_code

                if status >= 500:
                    server_errors.append(url)
                    continue

                if status != 200:
                    if url.startswith(base_url): # Only report internal broken links as "broken" in this context usually, but user wants check.
                        broken_links.append(url)
                    continue

                # Only parse HTML for recursion
                if "text/html" not in r.headers.get("Content-Type", ""):
                    continue

                soup = BeautifulSoup(r.text, "html.parser")

                # SEO CHECK (Only for internal pages)
                if url.startswith(base_url):
                    if not soup.title or not soup.title.string or not soup.title.string.strip():
                        seo_issues.append(f"Title eksik -> {url}")
                    if not soup.find("meta", attrs={"name": "description"}):
                        seo_issues.append(f"Description eksik -> {url}")

                # LINK SCAN
                for a in soup.find_all("a", href=True):
                    link = urljoin(url, a["href"])
                    
                    # Recursion condition: Internal & Not visited
                    if link.startswith(base_url):
                        if link not in visited and link not in to_visit:
                            to_visit.append(link)
                    
                    # We could check external links status here too if requested, 
                    # but for now let's stick to the queue-based crawler logic which validates as it goes.

                # IMAGE SCAN
                for img in soup.find_all("img", src=True):
                    img_url = urljoin(url, img["src"])
                    try:
                        # Head request is faster for images
                        ir = requests.head(img_url, timeout=3)
                        if ir.status_code != 200:
                            missing_images.append(img_url)
                    except:
                        # Retry with GET if HEAD fails (some servers block HEAD)
                        try:
                            ir = requests.get(img_url, timeout=3, stream=True)
                            if ir.status_code != 200:
                                missing_images.append(img_url)
                        except:
                            missing_images.append(img_url)

            except Exception as e:
                server_errors.append(f"{url} ({str(e)})")

        # AKILLI DUZELTME ONERISI
        for link in broken_links:
            try:
                parsed = urlparse(link)
                if parsed.path and "/" in parsed.path:
                    # /foo/bar -> /foo/index.html suggestion
                    path_parts = parsed.path.rstrip("/").split("/")
                    if len(path_parts) > 0:
                        suggestion = "/".join(path_parts[:-1]) + "/index.html"
                        fix_suggestions.append(f"{link} -> Belki: {suggestion}")
            except:
                pass

        return {
            "broken_links": broken_links,
            "missing_images": list(set(missing_images)),
            "server_errors": server_errors,
            "seo_issues": seo_issues,
            "fix_suggestions": fix_suggestions
        }

    loop = asyncio.get_event_loop()
    return await loop.run_in_executor(executor, _run_full_scan)

# --- DEEP AUDIT V2 (Recursive Engine) ---
# --- DEEP AUDIT V2 (Async Background) ---
deep_audit_instance = None

@app.get("/admin/deep-audit/start")
async def deep_audit_start(background_tasks: BackgroundTasks):
    """
    Starts the Deep Audit Engine in the background.
    """
    global deep_audit_instance
    if not DeepAuditEngine:
        return {"error": "Deep Audit Engine module missing!"}

    base_url = f"http://localhost:{PORT}"
    
    # Create new instance and start
    deep_audit_instance = DeepAuditEngine(base_url, max_depth=5, max_pages=500, rate_limit=0.1)
    
    # Add to background tasks (run call assumes synchronous logic, so we wrap it if needed or let FastAPI handle it if it's async safe, 
    # but DeepAuditEngine.run is blocking IO. Better to run in threadpool via background task wrapper?)
    # Since background_tasks.add_task runs in a threadpool for def functions, and DeepAuditEngine.run is synchronous IO-bound:
    background_tasks.add_task(deep_audit_instance.run)
    
    return {"status": "started", "msg": "Audit background task initiated."}

@app.get("/admin/deep-audit/status")
async def deep_audit_status():
    """
    Returns the live status of the running audit.
    """
    global deep_audit_instance
    if not deep_audit_instance:
        return {"status": "IDLE", "summary": {}}
    
    # Return quick stats
    return {
        "status": deep_audit_instance.status,
        "scanned_pages": deep_audit_instance.scanned_count,
        "total_discovered": deep_audit_instance.total_discovered,
        "broken_links": len(deep_audit_instance.broken_links),
        "missing_assets": len(deep_audit_instance.missing_assets),
        "server_errors": len(deep_audit_instance.server_errors)
    }

@app.get("/admin/deep-audit/report")
async def deep_audit_report():
    """
    Returns the full JSON report.
    """
    global deep_audit_instance
    if not deep_audit_instance:
        return {"error": "No audit data available."}
    
    return deep_audit_instance.get_report()

@app.get("/admin/deep-audit/report-pdf")
async def deep_audit_report_pdf():
    """
    Generates and returns a PDF report of the latest audit.
    """
    global deep_audit_instance
    if not deep_audit_instance:
        return {"error": "No audit data available. Please run an audit first."}
    
    report_data = deep_audit_instance.get_report()
    file_path = "audit_report.pdf"
    
    # PDF GENERATION LOGIC
    c = canvas.Canvas(file_path, pagesize=A4)
    width, height = A4
    
    # HEADER
    c.setFillColor(HexColor("#1a1a1a"))
    c.rect(0, height - 80, width, 80, fill=True, stroke=False)
    
    c.setFillColor(colors.white)
    c.setFont("Helvetica-Bold", 24)
    c.drawString(30, height - 50, "SANTIS DEEP AUDIT REPORT")
    
    c.setFont("Helvetica", 10)
    c.drawString(30, height - 70, f"Simulated Date: 2026-02-08 | Status: {report_data.get('status', 'IDLE')}")

    y = height - 120
    
    # SUMMARY SECTION
    c.setFillColor(colors.black)
    c.setFont("Helvetica-Bold", 16)
    c.drawString(30, y, "EXECUTIVE SUMMARY")
    y -= 25
    
    summary = report_data.get("summary", {})
    stats = [
        f"Scanned Pages: {summary.get('scanned_pages', 0)}",
        f"Broken Links: {summary.get('broken_links_count', 0)}",
        f"Missing Assets: {summary.get('missing_assets_count', 0)}",
        f"Server Errors: {summary.get('server_errors_count', 0)}",
        f"SEO Issues: {summary.get('seo_issues_count', 0)}"
    ]
    
    c.setFont("Helvetica", 12)
    for stat in stats:
        c.drawString(40, y, f"â€¢ {stat}")
        y -= 20
        
    y -= 20
    c.line(30, y, width - 30, y)
    y -= 30

    def draw_section_items(title, items, color):
        nonlocal y
        if not items: return

        if y < 100:
            c.showPage()
            y = height - 50
        
        c.setFillColor(color)
        c.setFont("Helvetica-Bold", 14)
        c.drawString(30, y, f"{title} ({len(items)})")
        y -= 20
        c.setFillColor(colors.black)
        c.setFont("Helvetica", 10)

        for item in items[:50]:
            if y < 50:
                c.showPage()
                y = height - 50
                c.setFont("Helvetica", 10)
            
            text = str(item.get("url", item))
            status = str(item.get("status", ""))
            c.drawString(40, y, f"â€¢ {text} [{status}]")
            y -= 15
        
        if len(items) > 50:
            c.drawString(40, y, f"... {len(items)-50} more items ...")
            y -= 20
        
        y -= 20

    draw_section_items("BROKEN LINKS", report_data.get("broken_links", []), colors.red)
    draw_section_items("MISSING ASSETS", report_data.get("missing_assets", []), colors.orange)
    draw_section_items("SERVER ERRORS", report_data.get("server_errors", []), colors.darkred)
    draw_section_items("SEO ISSUES", report_data.get("seo_issues", []), colors.blue)

    c.save()
    return FileResponse(file_path, filename="Santis_Audit_Report.pdf", media_type="application/pdf")

# --- ULTRA MEGA AUTO-FIX ENDPOINTS ---

@app.get("/admin/deep-audit/fix/images")
async def fix_missing_images():
    """
    Triggers the Self-Healing Image mechanism.
    """
    global deep_audit_instance
    if not deep_audit_instance:
        return {"error": "No audit data. Run Deep Audit first."}
    
    report = deep_audit_instance.heal_missing_images()
    return report

@app.get("/admin/deep-audit/fix/links")
async def fix_broken_links():
    """
    Triggers the Intelligent Link Fixer.
    """
    global deep_audit_instance
    if not deep_audit_instance:
        return {"error": "No audit data. Run Deep Audit first."}
    
    report = deep_audit_instance.fix_broken_links()
    return report

@app.get("/admin/deep-audit/fix/sitemap")
async def generate_sitemap():
    """
    Generates sitemap.xml.
    """
    
    # Use the dedicated sitemap generator (Database driven)
    try:
        # Run in threadpool to avoid blocking loop
        loop = asyncio.get_running_loop()
        report = await loop.run_in_executor(None, sitemap_generator.generate_sitemap)
        return report
    except Exception as e:
        return {"status": "error", "msg": str(e)}
    return report

# --- ACTIVE REPAIR MODULES (V100 FIXERS) ---

@app.post("/admin/fix/{module}")
async def run_fix_module(module: str):
    """
    Handles Ghost Layer Hunter, UTF-8 Sanitizer, Asset Intelligence.
    """
    try:
        loop = asyncio.get_event_loop()
        
        if module == "ghost":
            # Removes ._* files and .DS_Store
            def clean_ghosts():
                count = 0
                for root, dirs, files in os.walk("."):
                    if "venv" in root or ".git" in root: continue
                    for f in files:
                        if f.startswith("._") or f == ".DS_Store" or f == "Thumbs.db":
                            try:
                                os.remove(os.path.join(root, f))
                                count += 1
                            except: pass
                return count
                
            count = await loop.run_in_executor(None, clean_ghosts)
            logger.info(f"Ghost fix complete: {count} files removed.")
            return {"status": "success", "total_fixed": count, "message": "Ghost files removed."}

        elif module == "utf8":
            # Scans HTML/JS/CSS files and ensures they are UTF-8 compliant
            def scan_utf8():
                issues = []
                for root, dirs, files in os.walk("."):
                    if "venv" in root or ".git" in root or "node_modules" in root: continue
                    for f in files:
                        if f.endswith((".html", ".js", ".css", ".json")):
                            path = os.path.join(root, f)
                            try:
                                with open(path, "r", encoding="utf-8") as f_obj:
                                    f_obj.read()
                            except UnicodeDecodeError:
                                issues.append(path)
                            except Exception:
                                pass
                return issues

            issues = await loop.run_in_executor(None, scan_utf8)
            logger.info(f"UTF-8 scan complete: {len(issues)} issues found.")
            if not issues:
                return {"status": "success", "total_fixed": 0, "message": "All files are valid UTF-8."}
            else:
                return {"status": "warning", "issues": issues, "message": f"{len(issues)} files have encoding issues."}

        elif module == "optimize":
            # Asset Intelligence: Find images > 500KB
            def scan_large_images():
                large_files = []
                if not os.path.exists("assets"): return []
                for root, dirs, files in os.walk("assets"):
                    for f in files:
                        if f.lower().endswith((".jpg", ".jpeg", ".png", ".webp")):
                            path = os.path.join(root, f)
                            try:
                                size = os.path.getsize(path)
                                if size > 500 * 1024: # 500KB
                                    large_files.append({"path": path, "size_kb": round(size/1024, 1)})
                            except: pass
                return large_files

            large_files = await loop.run_in_executor(None, scan_large_images)
            logger.info(f"Optimization scan complete: {len(large_files)} large images found.")
            return {
                "status": "success", 
                "issues": large_files, # App expects 'issues' for scan results
                "message": f"Found {len(large_files)} large images (>500KB)."
            }
        
        return {"error": f"Unknown module: {module}"}
    except Exception as e:
        logger.error(f"Fix Module Error ({module}): {e}")
        raise HTTPException(status_code=500, detail=str(e))

# --- VISUAL AUDIT ENDPOINT ---

class VisualAuditRequest(BaseModel):
    url: str
    update_reference: bool = False

@app.post("/admin/visual-audit")
async def run_visual_audit(req: VisualAuditRequest):
    """
    Runs visual regression test on a specific URL.
    """
    try:
        global visual_audit_instance
        if not visual_audit_instance:
             # Try reloading (JIT)
            try:
                from visual_audit import VisualAuditEngine
                visual_audit_instance = VisualAuditEngine()
            except ImportError:
                return {"error": "Visual Audit Module not loaded (Playwright missing?)"}
            except Exception as e:
                return {"error": f"Visual Engine Init Failed: {e}"}

        # Construct full URL if relative
        target_url = req.url
        if not target_url.startswith("http"):
            # Assume localhost
            target_url = f"http://localhost:{PORT}/{target_url.lstrip('/')}"
        
        logger.info(f"ðŸ‘ï¸ Visual Audit Request for: {target_url}")
        # Run Sync Playwright in ThreadPool to avoid Windows Asyncio Loop issues
        loop = asyncio.get_event_loop()
        result = await loop.run_in_executor(
            None, 
            lambda: visual_audit_instance.capture_and_compare(target_url, update_reference=req.update_reference)
        )
        return result
    except Exception as e:
        logger.error(f"Visual Audit Error: {e}")
        return {"error": f"Critical Error in Visual Audit: {str(e)}"}

# --- PERFORMANCE AUDIT ENDPOINT ---

class PerformanceAuditRequest(BaseModel):
    url: str

@app.post("/admin/performance-audit")
async def run_performance_audit(req: PerformanceAuditRequest):
    """
    Runs performance audit on a specific URL.
    """
    try:
        global performance_audit_instance
        if not performance_audit_instance:
             # Try reloading (JIT)
            try:
                from performance_audit import PerformanceAuditEngine
                performance_audit_instance = PerformanceAuditEngine()
            except ImportError:
                 return {"error": "Performance Audit Module not loaded (Playwright missing?)"}
            except Exception as e:
                return {"error": f"Performance Engine Init Failed: {e}"}

        # Construct full URL if relative
        target_url = req.url
        if not target_url.startswith("http"):
            # Assume localhost
            target_url = f"http://localhost:{PORT}/{target_url.lstrip('/')}"
        
        logger.info(f"âš¡ Performance Audit Request for: {target_url}")
        
        # Run Sync Playwright in ThreadPool
        loop = asyncio.get_event_loop()
        result = await loop.run_in_executor(
            None, 
            lambda: performance_audit_instance.run_performance_test(target_url)
        )
        return result
    except Exception as e:
        logger.error(f"Performance Audit Error: {e}")
        return {"error": f"Critical Error in Performance Audit: {str(e)}"}

# --- SECURITY AUDIT ENDPOINT ---

class SecurityAuditRequest(BaseModel):
    url: str

@app.post("/admin/security-audit")
async def run_security_audit(req: SecurityAuditRequest):
    """
    Runs security audit on a specific URL.
    """
    try:
        global security_audit_instance
        if not security_audit_instance:
             # Try reloading (JIT)
            try:
                from security_audit import SecurityAuditEngine
                security_audit_instance = SecurityAuditEngine()
            except ImportError:
                 return {"error": "Security Audit Module not loaded."}
            except Exception as e:
                return {"error": f"Security Engine Init Failed: {e}"}

        # Construct full URL if relative
        target_url = req.url
        if not target_url.startswith("http"):
            # Assume localhost
            target_url = f"http://localhost:{PORT}/{target_url.lstrip('/')}"
        
        logger.info(f"ðŸ›¡ï¸ Security Audit Request for: {target_url}")
        
        # Requests is sync, run in executor
        loop = asyncio.get_event_loop()
        result = await loop.run_in_executor(None, security_audit_instance.run_security_scan, target_url)
        return result
    except Exception as e:
        logger.error(f"Security Audit Error: {e}")
        return {"error": f"Critical Error in Security Audit: {str(e)}"}

# --- AI FIX SUGGESTIONS ENDPOINT ---

@app.get("/admin/ai-fix-suggestions")
async def ai_fix_suggestions():
    """
    Combines Security and Performance audit results and generates AI suggestions.
    """
    try:
        global security_audit_instance, performance_audit_instance
        
        if not generate_suggestions:
            return {"error": "AI Suggestions Module not loaded."}

        # Run Audits (Lightweight)
        security_data = {}
        performance_data = {}
        
        target_url = f"http://localhost:{PORT}/" # Default to root

        # 1. Security Scan
        if security_audit_instance:
             loop = asyncio.get_event_loop()
             security_data = await loop.run_in_executor(None, security_audit_instance.run_security_scan, target_url)

        # 2. Performance Scan (Mock or Recent)
        # Performance is heavy (Playwright), so ideally we use cached results.
        # For V1, we will trigger a fresh quick scan or use defaults if busy.
        if performance_audit_instance:
             try:
                performance_data = await performance_audit_instance.run_performance_test(target_url)
             except:
                performance_data = {"error": "Skipped perf scan"}

        # Combine Data
        combined_audit = {
            "security": security_data,
            "performance": performance_data
        }

        # Generate Suggestions
        suggestions = generate_suggestions(combined_audit)
        return suggestions

    except Exception as e:
        logger.error(f"AI Brain Error: {e}")
        return [{"category":"ERROR", "issue":f"AI Error: {str(e)}", "fix":"Check server logs."}]

# --- ATTACK SIMULATOR ENDPOINT ---
@app.post("/admin/attack-simulator")
async def run_attack_simulation():
    """
    Runs a live attack simulation against localhost.
    """
    try:
        global attack_simulator_instance
        if not attack_simulator_instance:
             # Just in case import failed initially
            try:
                from attack_simulator import AttackSimulatorEngine
                attack_simulator_instance = AttackSimulatorEngine()
            except ImportError:
                return {"error": "Attack Simulator Module not loaded."}

        target_url = f"http://localhost:{PORT}/"
        
        # Run in thread
        loop = asyncio.get_event_loop()
        result = await loop.run_in_executor(None, attack_simulator_instance.run_simulation, target_url)
        return result
    except Exception as e:
        logger.error(f"Attack Sim Error: {e}")
        return {"error": str(e)}

# --- STATICS & BOOT ---
app.mount("/admin", StaticFiles(directory="admin", html=True), name="admin")
app.mount("/data", StaticFiles(directory="data"), name="data")
app.mount("/assets", StaticFiles(directory="assets"), name="assets")
app.mount("/", StaticFiles(directory=".", html=True), name="root")

if __name__ == "__main__":
    logger.info(f"ðŸ¦… SANTIS SENTINEL V3 STARTING (AIOFILES={'YES' if HAS_AIOFILES else 'NO'})")
    uvicorn.run("server:app", host="0.0.0.0", port=PORT, reload=True)
